{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTDLmA1Q-BWH"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqYv0Wot0H5o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2CkgRbVKyS3"
      },
      "source": [
        "### Defining Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eos84TxIK2Cd"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 20\n",
        "image_dim = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbFGvEGd977p"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "sKR7hq3qCOne",
        "outputId": "88f0d3c5-9538-4315-d177-3db3dccdc861"
      },
      "outputs": [],
      "source": [
        "# Not used in training script, just used to determine mean and standard deviation\n",
        "# for normalization\n",
        "\n",
        "'''\n",
        "mean = std = 0.0\n",
        "trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "for images, _ in trainset:\n",
        "  images = images.view(3, -1) # 3 for 3 channels (RGB)\n",
        "  mean += images.mean(1)\n",
        "  std += images.std(1)\n",
        "\n",
        "# Calculate the means\n",
        "mean /= len(trainset)\n",
        "std /= len(trainset)\n",
        "\n",
        "print(f'mean: {mean} std: {std}')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ5aAxEV-NMJ"
      },
      "outputs": [],
      "source": [
        "mean = [0.5071, 0.4866, 0.4409]\n",
        "std = [0.2009, 0.1984, 0.2023]\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EdW0s9O8fhy",
        "outputId": "ee5faf84-7637-4f07-d47b-fac5fe78d0e6"
      },
      "outputs": [],
      "source": [
        "train_set = datasets.CIFAR100(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_set = datasets.CIFAR100(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgdOUkYJExqp",
        "outputId": "89532df7-e481-44f1-a644-51d546a56874"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_set = datasets.CIFAR100(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC7_h3jt-pWA"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LouGjFthyQ2"
      },
      "source": [
        "### Defining CNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCU8vfJr3bTL"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3, 3), padding=1)\n",
        "        self.act1 = nn.ReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1)\n",
        "        self.act2 = nn.ReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 3), padding=1)\n",
        "        self.act3 = nn.ReLU()\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.conv1(x))\n",
        "        x = self.act1(x)\n",
        "\n",
        "        x = self.pool(self.conv2(x))\n",
        "        x = self.act2(x)\n",
        "\n",
        "        x = self.pool(self.conv3(x))\n",
        "        x = self.act3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.fc4(x)\n",
        "\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUitQ2B7JAgt"
      },
      "outputs": [],
      "source": [
        "model = CNN()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "val_loss_history = []\n",
        "val_acc_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_function(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  print(f'Epoch #: {epoch + 1}')\n",
        "  # Validation\n",
        "  model.eval()\n",
        "  val_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      images, labels = data\n",
        "      outputs = model(images)\n",
        "      loss = loss_function(outputs, labels)\n",
        "      val_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(test_loader)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_loss_history.append(val_loss)\n",
        "    val_acc_history.append(val_accuracy)\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "print('training complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm02JPla5YyI"
      },
      "source": [
        "### **Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "T99vwYTLNRlH",
        "outputId": "04ea815c-b842-4188-f3ff-e7fc4b79b8e4"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "  print('Accuracy on the test set: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgUqHb-t6C91"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "ks01T-Db6Esb",
        "outputId": "5e16493c-ba6f-408e-94b7-5aa10210eaed"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(val_loss_history, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Validation Loss per Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(val_acc_history, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Validation Accuracy per Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
